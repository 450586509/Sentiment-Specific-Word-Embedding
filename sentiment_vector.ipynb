{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import  join\n",
    "import re\n",
    "import keras\n",
    "from keras.layers import Embedding, Lambda, Dense\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_str(string, TREC=False):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Every dataset is lower cased except for TREC\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"<br />\", \"\", string) \n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)     \n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string) \n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string) \n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string) \n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string) \n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string) \n",
    "    string = re.sub(r\",\", \" , \", string) \n",
    "    string = re.sub(r\"!\", \" ! \", string) \n",
    "    string = re.sub(r\"\\(\", \" ( \", string) \n",
    "    string = re.sub(r\"\\)\", \" ) \", string) \n",
    "    string = re.sub(r\"\\?\", \" ? \", string) \n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)    \n",
    "    return string.strip().lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 每次产生一个Batch的数据生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构造训练数据\n",
    "#path = '/home/bruce/data/sentiment/origin/sentiment_w2v/'\\\n",
    "#path = '/home/bruce/data/sentiment/origin/test'\n",
    "def lines_Generator(files_path=''):\n",
    "    for name in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path,name)):\n",
    "            print('file name =',name)\n",
    "            for line in open(os.path.join(path,name)):\n",
    "                yield clean_str(line)\n",
    "def ngram_Generator(lines_generator = None,ngram=None):\n",
    "    for line in lines_generator:\n",
    "        if len(line) <= ngram:\n",
    "            continue\n",
    "        label = int(line[0:1])\n",
    "        words = line[2:].split(' ')\n",
    "        right = ngram\n",
    "        for right in range(right , len(words) + 1 , 1):\n",
    "            if len(words)>=ngram:\n",
    "                yield (words[right-ngram:right],label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_index(data_path=''):\n",
    "    word_index ={}\n",
    "    count = 1\n",
    "    for line in lines_Generator(files_path=data_path):\n",
    "        words = line[2:].split(' ')\n",
    "        for word in words:\n",
    "            if word not in word_index:\n",
    "                word_index[word] = count\n",
    "                count = count + 1\n",
    "    print('length of word_index = ',len(word_index))\n",
    "    return word_index \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word 转 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_Generator(ngram_generator=None,batch_size = None):\n",
    "    batch_x =[]\n",
    "    batch_y = []\n",
    "    for ng in ngram_generator:\n",
    "        indexs = [word_index[w] for w in ng[0]]\n",
    "        batch_x.append(indexs)\n",
    "        if ng[1] == 0:\n",
    "            batch_y.append([1,0])\n",
    "        else:\n",
    "            batch_y.append([0,1])\n",
    "        if len(batch_x) == batch_size:\n",
    "            yield batch_x,batch_y\n",
    "            batch_x =[]\n",
    "            batch_y =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name = all_data.txt\n",
      "length of word_index =  119099\n"
     ]
    }
   ],
   "source": [
    "path = '/home/bruce/data/sentiment/origin/sentiment_w2v'\n",
    "word_index = get_word_index(data_path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 8, 100)\n",
      "[None, 8, 100]\n",
      "(None, 100)\n"
     ]
    }
   ],
   "source": [
    "ngram = 8\n",
    "max_dim = len(word_index) + 1\n",
    "batch_size = 50\n",
    "embedding_dim = 100\n",
    "def sum_tensor(x,axis=-2):\n",
    "    return K.sum(x,axis=axis)\n",
    "\n",
    "def get_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    print(shape)\n",
    "    assert len(shape) == 3  # only valid for 2D tensors\n",
    "    return (None,embedding_dim)\n",
    "\n",
    "def get_model(max_dim = max_dim,embedding_dim = embedding_dim,ngram = ngram):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=max_dim,output_dim=embedding_dim,input_length = ngram))\n",
    "    print (model.output_shape)\n",
    "    \n",
    "    model.add(Lambda(sum_tensor,output_shape=get_output_shape))\n",
    "    print (model.output_shape)\n",
    "    model.add(Dense(output_dim=embedding_dim,activation='hard_sigmoid'))\n",
    "    model.add(Dense(output_dim=2,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "    return model\n",
    "model = get_model(max_dim = max_dim,embedding_dim = embedding_dim,ngram = ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"337pt\" viewBox=\"0.00 0.00 261.00 337.00\" width=\"261pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 333)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-333 257,-333 257,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139659092669832 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139659092669832</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 253,-328.5 253,-292.5 0,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"126.5\" y=\"-306.8\">embedding_input_5 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 139659092670056 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139659092670056</title>\n",
       "<polygon fill=\"none\" points=\"22,-219.5 22,-255.5 231,-255.5 231,-219.5 22,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"126.5\" y=\"-233.8\">embedding_5 (Embedding)</text>\n",
       "</g>\n",
       "<!-- 139659092669832&#45;&gt;139659092670056 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139659092669832-&gt;139659092670056</title>\n",
       "<path d=\"M126.5,-292.313C126.5,-284.289 126.5,-274.547 126.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"130,-265.529 126.5,-255.529 123,-265.529 130,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139659092687112 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139659092687112</title>\n",
       "<polygon fill=\"none\" points=\"47.5,-146.5 47.5,-182.5 205.5,-182.5 205.5,-146.5 47.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"126.5\" y=\"-160.8\">lambda_5 (Lambda)</text>\n",
       "</g>\n",
       "<!-- 139659092670056&#45;&gt;139659092687112 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139659092670056-&gt;139659092687112</title>\n",
       "<path d=\"M126.5,-219.313C126.5,-211.289 126.5,-201.547 126.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"130,-192.529 126.5,-182.529 123,-192.529 130,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139659092687280 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139659092687280</title>\n",
       "<polygon fill=\"none\" points=\"59.5,-73.5 59.5,-109.5 193.5,-109.5 193.5,-73.5 59.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"126.5\" y=\"-87.8\">dense_9 (Dense)</text>\n",
       "</g>\n",
       "<!-- 139659092687112&#45;&gt;139659092687280 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139659092687112-&gt;139659092687280</title>\n",
       "<path d=\"M126.5,-146.313C126.5,-138.289 126.5,-128.547 126.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"130,-119.529 126.5,-109.529 123,-119.529 130,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139659092686608 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139659092686608</title>\n",
       "<polygon fill=\"none\" points=\"55,-0.5 55,-36.5 198,-36.5 198,-0.5 55,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"126.5\" y=\"-14.8\">dense_10 (Dense)</text>\n",
       "</g>\n",
       "<!-- 139659092687280&#45;&gt;139659092686608 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139659092687280-&gt;139659092686608</title>\n",
       "<path d=\"M126.5,-73.3129C126.5,-65.2895 126.5,-55.5475 126.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"130,-46.5288 126.5,-36.5288 123,-46.5289 130,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0\n",
      "file name = all_data.txt\n",
      "batch =0 ,result =[array(0.20701661705970764, dtype=float32), array(1.0, dtype=float32)] \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    print('epoch = ',epoch)\n",
    "    lines_ge = lines_Generator(files_path=path)\n",
    "    ngram_ge = ngram_Generator(lines_generator=lines_ge,ngram=ngram)\n",
    "    batch_count = 0\n",
    "    for batch in batch_Generator(ngram_generator=ngram_ge,batch_size=batch_size):\n",
    "        history = model.train_on_batch(batch[0],batch[1])\n",
    "        if batch_count % 10000 == 0:\n",
    "            print('batch ={0} ,result ={1} '.format(batch_count,history))\n",
    "        batch_count = batch_count + 1 \n",
    "    print('saving model')\n",
    "    model.save('/home/bruce/model/sen2vec_model_{}.h5'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
